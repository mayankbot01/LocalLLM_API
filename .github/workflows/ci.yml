# =============================================================================
# .github/workflows/ci.yml - LocalLLM_API CI Pipeline
# =============================================================================
# Runs on every push and pull request to main.
# Lints, tests, and builds the Docker image.
# =============================================================================
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    name: Lint & Test
    runs-on: ubuntu-latest
    env:
      # Dummy values so config.py (pydantic settings) can import without error
      ADMIN_SECRET: ci_test_secret
      SUPABASE_URL: https://example.supabase.co
      SUPABASE_SERVICE_KEY: eyJci_dummy_key
      OLLAMA_BASE_URL: http://localhost:11434
      API_KEY_PREFIX: llm
      DEFAULT_RATE_LIMIT_PER_MIN: "20"
      DEFAULT_MONTHLY_TOKEN_LIMIT: "1000000"
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Lint with ruff (non-blocking)
        run: |
          pip install ruff
          ruff check . --exit-zero
        continue-on-error: true

      - name: Run tests
        run: |
          pytest tests/ -v --tb=short --cov=. --cov-report=term-missing

  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: localllm_api:ci
          cache-from: type=gha
          cache-to: type=gha,mode=max
